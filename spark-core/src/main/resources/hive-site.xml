<configuration>
    <!-- 存储元数据mysql相关配置 -->
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value> jdbc:mysql://10.11.1.151:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8</value>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>up_dbuser</value>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionPassword</name>R
        <value>up@DBuser#2021_ffcs</value>
    </property>

    <!-- H2S运行绑定host -->
    <property>
        <name>hive.server2.thrift.bind.host</name>
        <value>hadoop140</value>
    </property>

    <!-- 远程模式部署metastore 服务地址 -->
    <property>
        <name>hive.metastore.uris</name>
        <value>thrift://hadoop140:9083</value>
    </property>

    <!-- 关闭元数据存储授权  -->
    <property>
        <name>hive.metastore.event.db.notification.api.auth</name>
        <value>false</value>
    </property>

    <!-- 关闭元数据存储版本的验证 -->
    <property>
        <name>hive.metastore.schema.verification</name>
        <value>false</value>
    </property>

    <property>
	  <name>hive.server2.transport.mode</name>
	  <value>binary</value>
    </property>
    <property>
	  <name>hive.server2.thrift.port</name>
	  <value>10000</value>
    </property>
    
    <property>
    	<name>hive.exec.debug.localtask</name>
    	<value>true</value>
    </property>
    <property>
    	<name>hive.mapred.mode</name>
    	<value>nonstrict</value>
    </property>

	<property>
	  <name>hive.metastore.sasl.enabled</name>
	  <value>false</value>
	  <description>If true, the metastore Thrift interface will be secured with SASL. Clients must authenticate with Kerberos.</description>
	</property>
	 
	<property>
	  <name>hive.server2.enable.doAs</name>
	  <value>false</value>
	</property>
	 
	<property>
	  <name>hive.server2.authentication</name>
	  <value>NONE</value>
	</property>

  <property>
    <name>hive.support.concurrency</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.enforce.bucketing</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.exec.dynamic.partition.mode</name>
    <value>nonstrict</value>
  </property>
  <property>
    <name>hive.txn.manager</name>
    <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>
  </property>
    <property>
    <name>hive.compactor.initiator.on</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.compactor.worker.threads</name>
    <value>1</value>
  </property>

    <property>
        <name>dfs.client.use.datanode.hostname</name>
        <value>true</value>
    </property>
</configuration>
